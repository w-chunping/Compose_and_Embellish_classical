{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel died. Error: /usr/bin/python: No module named ipykernel_launcher... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# define miditok tokenizer config\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from symusic import Score\n",
    "import numpy as np\n",
    "\n",
    "BEAT_RES = {(0, 1): 24, (1, 2): 8, (2, 4): 4, (4, 8): 2}\n",
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": BEAT_RES,\n",
    "    \"num_velocities\": 24,\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\"],\n",
    "    \"use_chords\": True,\n",
    "    \"use_rests\": True,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": True,\n",
    "    \"use_programs\": False,  # no multitrack here\n",
    "    \"num_tempos\": 32,\n",
    "    \"tempo_range\": (50, 200),  # (min_tempo, max_tempo)\n",
    "}\n",
    "\n",
    "# Creating a multitrack tokenizer, read the doc to explore all the parameters\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "import pickle\n",
    "def read_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "dict_path = \"./stage02_embellish/vocab/skyline_miditok_vocab.pkl\"\n",
    "event2idx, idx2event = read_pickle(dict_path)\n",
    "\n",
    "def midi2txt(midi_path, txt_path):\n",
    "    midi = Score(midi_path)\n",
    "    tokens = tokenizer(midi)  # calling the tokenizer will automatically detect MIDIs, paths and tokens\n",
    "    with open(txt_path, \"w\") as file:\n",
    "        for item in tokens[0].tokens:\n",
    "            file.write(item + \"\\n\")\n",
    "\n",
    "def gnpy2midi(npy_path, midi_path=\"/content/test_from_npy.mid\"):\n",
    "    tokens = np.load(npy_path, allow_pickle=True)\n",
    "    #tokens = tokens.reshape(1, -1)\n",
    "    tokens = np.array([event2idx[e] for e in tokens]).reshape(1,-1)\n",
    "    converted_back_midi = tokenizer(tokens)\n",
    "    converted_back_midi.dump_midi(midi_path) # Save the MIDI file\n",
    "\n",
    "def pkl2txt(pkl_path, txt_path):\n",
    "    skyline_pos, midi_pos, all_events = read_pickle(pkl_path)\n",
    "    tokens = [all_events[pos[0]+1:pos[1]] for pos in skyline_pos]\n",
    "    flattened = [item for row in tokens for item in row]\n",
    "    \n",
    "    # truncate for testing\n",
    "    length = len(flattened)//10\n",
    "    flattened = flattened[:1000]\n",
    "\n",
    "    with open(txt_path, \"w\") as file:\n",
    "        for item in flattened:\n",
    "            file.write(item[\"name\"]+\"_\"+item[\"value\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def pkl2orig(pkl_path, orig_path):\n",
    "    skyline_pos, midi_pos, all_events = read_pickle(pkl_path)\n",
    "    tokens = [all_events[pos[0]+1:pos[1]] for pos in midi_pos]\n",
    "    flattened = [item for row in tokens for item in row]\n",
    "    \n",
    "    tokens = np.array([event2idx[e[\"name\"]+\"_\"+e[\"value\"]] for e in flattened]).reshape(1,-1)\n",
    "    converted_back_midi = tokenizer(tokens)\n",
    "    converted_back_midi.dump_midi(orig_path) # Save the MIDI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# test pkl2orig\n",
    "# pkl2orig(\"../dataset/gp-piano-parsed/ _60cemeCu6E.pkl\",\"test.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "midi2txt(\"../demos/46414_skyline.mid\",\"generation/stage01_testpieces/46414.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "train_split = read_pickle(\"stage02_embellish/pkl/train.pkl\")\n",
    "valid_split = read_pickle(\"stage02_embellish/pkl/valid.pkl\")\n",
    "compo_split = read_pickle(\"stage02_embellish/pkl/composer_split.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "to_test = [\"Bach_JohannSebastian\", \"Mozart_WolfgangAmadeus\", \"Beethoven_Ludwigvan\"]\n",
    "generation_split = {}\n",
    "\n",
    "for composer in to_test:\n",
    "    all_songs = compo_split[composer]\n",
    "    temp_train = random.sample([s for s in all_songs if f\" {s}.pkl\" in train_split],3)\n",
    "    temp_valid = random.sample([s for s in all_songs if f\" {s}.pkl\" in valid_split],2)\n",
    "    generation_split[composer] = {\"train\":temp_train, \"valid\":temp_valid, \"all\":temp_train+temp_valid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bach_JohannSebastian': {'train': ['7Dc3en1ntpM',\n",
       "   '6n3n6Ouw_4c',\n",
       "   'X9Z_FVjMSWc'],\n",
       "  'valid': ['feikrhaRFTk', 'dBj7TNg4uWs'],\n",
       "  'all': ['7Dc3en1ntpM',\n",
       "   '6n3n6Ouw_4c',\n",
       "   'X9Z_FVjMSWc',\n",
       "   'feikrhaRFTk',\n",
       "   'dBj7TNg4uWs']},\n",
       " 'Mozart_WolfgangAmadeus': {'train': ['5nwML8h89tw',\n",
       "   'SItm3YOLjmc',\n",
       "   'yHSPuZu0z4k'],\n",
       "  'valid': ['J9866zX07iw', '49oiE8Tj1UU'],\n",
       "  'all': ['5nwML8h89tw',\n",
       "   'SItm3YOLjmc',\n",
       "   'yHSPuZu0z4k',\n",
       "   'J9866zX07iw',\n",
       "   '49oiE8Tj1UU']},\n",
       " 'Beethoven_Ludwigvan': {'train': ['noAU3qDS1dA',\n",
       "   '0_5iQCV62S4',\n",
       "   'yibghhX9TdA'],\n",
       "  'valid': ['LFZxrkiWvMU', 'wxR-khJsx3s'],\n",
       "  'all': ['noAU3qDS1dA',\n",
       "   '0_5iQCV62S4',\n",
       "   'yibghhX9TdA',\n",
       "   'LFZxrkiWvMU',\n",
       "   'wxR-khJsx3s']}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "test_composer = \"mozart\"\n",
    "postfix = \"finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for piece in generation_split[\"Mozart_WolfgangAmadeus\"][\"all\"]:\n",
    "    generation_home = \"/home/yihsin/MidiStyleTransfer/Compose_and_Embellish_classical/generation\"\n",
    "    pkl_file = f\"/home/yihsin/MidiStyleTransfer/dataset/gp-piano-parsed/ {piece}.pkl\"\n",
    "\n",
    "    if not os.path.exists(f\"{generation_home}/stage01_{test_composer}{postfix}\"):\n",
    "        os.makedirs(f\"{generation_home}/stage01_{test_composer}{postfix}\")\n",
    "\n",
    "    pkl2txt(\n",
    "        pkl_file, \n",
    "        f\"{generation_home}/stage01_{test_composer}{postfix}/{piece}.txt\")\n",
    "    \n",
    "    if not os.path.exists(f\"{generation_home}/stage02_{test_composer}{postfix}\"):\n",
    "        os.makedirs(f\"{generation_home}/stage02_{test_composer}{postfix}\")\n",
    "        \n",
    "    pkl2orig(\n",
    "        pkl_file,\n",
    "        f\"/home/yihsin/MidiStyleTransfer/Compose_and_Embellish_classical/generation/stage02_{test_composer}{postfix}/{piece}.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preparing data] now at #0\n",
      "[preparing data] now at #200\n",
      "2025-04-16 10:01:10.764062: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 10:01:10.769544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2025-04-16 10:01:10.769568: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "[info] model init completed\n",
      "[info] temp = 1.2 | top_p = 0.97\n",
      "loading check point from: ckpt/random_mask_mozart/params/ep700_loss0.912_params.pt\n",
      "[info] model loaded\n",
      "[# pieces] 1\n",
      "[info] generated 1 bars, #events = 113\n",
      "[info] generated 2 bars, #events = 346\n",
      "[info] generated 3 bars, #events = 607\n",
      "[info] generated 4 bars, #events = 740\n",
      "[info] generated 5 bars, #events = 1165\n",
      "[info] generated 6 bars, #events = 1483\n",
      "[info] generated 7 bars, #events = 1790\n",
      "[info] generated 8 bars, #events = 2027\n",
      "[info] generated 9 bars, #events = 2169\n",
      "-- generated events: 2169\n",
      "-- time elapsed  : 25.29 secs\n",
      "-- time per event: 0.01 secs\n"
     ]
    }
   ],
   "source": [
    "!python3 stage02_embellish/inference.py \\\n",
    "  stage02_embellish/config/gp_gpt2.yaml \\\n",
    "  generation/stage01_testpieces\\\n",
    "  generation/stage02_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "generation_home = \"/home/yihsin/MidiStyleTransfer/Compose_and_Embellish_classical/generation\"\n",
    "for g in os.listdir(f\"{generation_home}/stage02_{test_composer}{postfix}\"):\n",
    "    if(g.split(\".\")[1]==\"npy\"):\n",
    "        idx = g.split(\".\")[0]\n",
    "        gnpy2midi(\n",
    "            f\"{generation_home}/stage02_{test_composer}{postfix}/{g}\",\n",
    "            #f\"{generation_home}/midi_samples_0413/{test_composer}/{idx}_finetuned.mid\"\n",
    "            f\"{generation_home}/midi_samples_0413/finetune/{idx}.mid\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "generation_home = \"/home/yihsin/MidiStyleTransfer/Compose_and_Embellish_classical/generation\"\n",
    "\n",
    "for g in os.listdir(f\"{generation_home}/stage02_test\"):\n",
    "    idx = g.split(\".\")[0]\n",
    "    gnpy2midi(\n",
    "        f\"{generation_home}/stage02_test/{g}\",\n",
    "        f\"{generation_home}/midi_samples_0413/_{g}.mid\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "midi2txt(\"generation/midi_samples/cmaj.mid\", \"generation/stage01/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "generation_home = \"/home/yihsin/MidiStyleTransfer/Compose_and_Embellish_classical/generation/\"\n",
    "gnpy2midi(\n",
    "    generation_home+\"stage02_gpt2_new/qjk_2stage_samp01.npy\", \n",
    "    generation_home+\"midi_samples/mozart_generated.mid\"\n",
    ")\n",
    "gnpy2midi(\n",
    "    generation_home+\"stage02_gpt2_new/qjk_skyline.npy\", \n",
    "    generation_home+\"midi_samples/mozart_skyline_condition.mid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "gnpy2midi(\n",
    "    generation_home+\"stage02_gpt2_new/bach_2stage_samp01.npy\", \n",
    "    generation_home+\"midi_samples/bach_generated.mid\"\n",
    ")\n",
    "gnpy2midi(\n",
    "    generation_home+\"stage02_gpt2_new/bach_skyline.npy\", \n",
    "    generation_home+\"midi_samples/bach_skyline_condition.mid\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
